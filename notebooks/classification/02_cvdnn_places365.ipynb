{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV DNN Scene Classification\n",
    "\n",
    "- use Places365 pre-trained models to analyze scenery\n",
    "- updated for OpenCV 3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os.path import join\n",
    "import cv2 as cv\n",
    "if not cv.__version__ == '3.4.2':\n",
    "  print('pip install opencv-python==3.4.2 or greater')\n",
    "import time\n",
    "import numpy as np\n",
    "import imutils\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from operator import itemgetter\n",
    "sys.path.append('/vframe/')\n",
    "#from utils import imx\n",
    "# from tools.config import notebooks as cfg\n",
    "# import tools.utils.imx as imx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset directories\n",
    "DIR_APP = '/data_store_nas/apps/vframe/'\n",
    "TEST_IMG_DIR = join(DIR_APP,'assets/img/test')\n",
    "DIR_MODELS = join(DIR_APP, 'models')\n",
    "# Model dir\n",
    "model_dir = osp.join(DIR_MODELS,'caffe/places365')\n",
    "\n",
    "# GoogleNet 365\n",
    "fp_model = osp.join(model_dir,'googlenet_places365/googlenet_places365.caffemodel')\n",
    "fp_prototxt = osp.join(model_dir,'googlenet_places365/deploy_googlenet_places365.prototxt')\n",
    "\n",
    "# ResNet152 365\n",
    "#fp_model = osp.join(model_dir,'resnet152_places365/resnet152_places365.caffemodel')\n",
    "#fp_prototxt = osp.join(model_dir,'resnet152_places365/deploy_resnet152_places365.prototxt')\n",
    "\n",
    "# VGG 365\n",
    "#fp_model = osp.join(model_dir,'vgg16_places365/vgg16_places365.caffemodel')\n",
    "#fp_prototxt = osp.join(model_dir,'vgg16_places365/deploy_vgg16_places365.prototxt')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 1365 classes\n",
    "\n",
    "# ResNet152 1365\n",
    "#fp_model = osp.join(model_dir,'resnet152_places365/resnet152_places365.caffemodel')\n",
    "#fp_prototxt = osp.join(model_dir,'resnet152_places365/deploy_resnet152_places365.prototxt')\n",
    "\n",
    "# VGG 1365\n",
    "#fp_model = osp.join(model_dir,'resnet152_places365/alexnet_places365.caffemodel')\n",
    "#fp_prototxt = osp.join(model_dir,'alexnet_places365/deploy_alexnet_places365.prototxt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 365 places\n",
    "# /a/airfield 0\n",
    "fp_categories = join(model_dir,'data/categories_places365.txt')\n",
    "\n",
    "# or, 1365 places\n",
    "#fp_categories = osp.join(model_dir,'data/categories_hybrid1365.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class labels\n",
    "classes = list()\n",
    "with open(fp_categories) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_store_nas/apps/vframe/assets/img/test/people-01.jpg\n",
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "# load image from test dir\n",
    "fp_im = osp.join(TEST_IMG_DIR,'people-01.jpg')\n",
    "print(fp_im)\n",
    "im = cv.imread(fp_im)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `cv2.dnn.blobFromImage` check `deploy.prototxt` for dimensions and mean value.\n",
    "\n",
    "This CNN requires fixed spatial dimensions for our input image(s) so we need to ensure it is resized to 224x224 pixels while performing mean subtraction (104, 117, 123) to normalize the input; after executing this command our \"blob\" now has the shape: (1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(cv2.dnn.readNetFromTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv.dnn.readNetFromCaffe(fp_prototxt, fp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the prototxt file throws an error, try using this at top of file:\n",
    "```\n",
    "input: \"data\"\n",
    "input_shape {\n",
    "  dim: 1\n",
    "  dim: 3\n",
    "  dim: 224\n",
    "  dim: 224\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] FPS 67.608\n"
     ]
    }
   ],
   "source": [
    "# calc FPS\n",
    "niters = 10\n",
    "st = time.time()\n",
    "for n in range(niters):\n",
    "    blob = cv.dnn.blobFromImage(im, 1, (224, 224), (104, 117, 123))\n",
    "    net.setInput(blob)\n",
    "    preds = net.forward()\n",
    "    \n",
    "fps = float(niters) / (time.time()-st)\n",
    "print(\"[INFO] FPS {:.5}\".format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191 186 309 187 305]\n"
     ]
    }
   ],
   "source": [
    "# sort the indexes of the probabilities in descending order (higher\n",
    "# probabilitiy first) and grab the top-5 predictions\n",
    "idxs = np.argsort(preds[0])[::-1][:5]\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]1. label: igloo, probability: 0.50725\n",
      "[INFO]2. label: ice_floe, probability: 0.19791\n",
      "[INFO]3. label: snowfield, probability: 0.072709\n",
      "[INFO]4. label: ice_shelf, probability: 0.071913\n",
      "[INFO]5. label: ski_slope, probability: 0.017611\n"
     ]
    }
   ],
   "source": [
    "# loop over the top-5 predictions and display them\n",
    "dst = im.copy()\n",
    "for (i, idx) in enumerate(idxs):\n",
    "    # draw the top prediction on the input image\n",
    "    if i == 0:\n",
    "        text = \"{} ({:.2f}%)\".format(classes[idx],\n",
    "            preds[0][idx] * 100)\n",
    "        cv.putText(dst, text, (20, 100),  cv.FONT_HERSHEY_SIMPLEX,\n",
    "            1.5, (0, 255,0), 2)\n",
    "        cv.putText(dst,'{:.2f} FPS'.format(fps),(20,40),cv.FONT_HERSHEY_SIMPLEX,\n",
    "            1.5,(0,255,0),2)\n",
    "        \n",
    "    print(\"[INFO]{}. label: {}, probability: {:.5}\".format(i + 1,\n",
    "        classes[idx], preds[0][idx]))\n",
    "\n",
    "# # display the output image\n",
    "# imx.pltimg(dst,mode='bgr')\n",
    "# print('{:.2f} FPS'.format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19791022 0.50725454]\n"
     ]
    }
   ],
   "source": [
    "pred_scores = preds[0]\n",
    "top_idxs = np.where(np.array(pred_scores) > 0.1)\n",
    "print(pred_scores[top_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 365)\n",
      "186 0.19791022\n",
      "191 0.50725454\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "\n",
    "for i, p in enumerate(pred_scores):\n",
    "  if float(p) > 0.1:\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 1 (array([], dtype=int64),) []\n"
     ]
    }
   ],
   "source": [
    "a = np.array([5, 6])\n",
    "b = np.where(a  > 10)\n",
    "print(bool(b), len(b), b, b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
